{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.autograd as autograd \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Cleaning Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_br = re.compile(r'<\\s*br\\s*/?>', re.IGNORECASE)\n",
    "def sub_br(x): return re_br.sub(\"\\n\", x)\n",
    "\n",
    "my_tok = spacy.load('en')\n",
    "def spacy_tok(x): return [tok.text for tok in my_tok.tokenizer(sub_br(x))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Encoding Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(content):\n",
    "    \"\"\"Computes Dict of counts of words.\n",
    "    \n",
    "    Computes the number of times a word is on a document.\n",
    "    \"\"\"\n",
    "    vocab = defaultdict(float)\n",
    "    for line in content:\n",
    "        for word in line.split():\n",
    "            vocab[word] += 1\n",
    "    return vocab\n",
    "\n",
    "def encode_sentence(x, vocab2index, N=26, padding_start=True):\n",
    "    enc = np.zeros(N, dtype=np.int32)\n",
    "    enc1 = [vocab2index.get(w, vocab2index[\"UNK\"]) for w in x.split()]\n",
    "    l = min(N, len(enc1))\n",
    "    if padding_start:\n",
    "        enc[N-l:] = enc1[:l]\n",
    "    else:\n",
    "        enc = enc1[:l]\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, X, y, N = 26, padding_start = True):\n",
    "        self.X = np.array([encode_sentence(x,vocab2index, N, padding_start) for x in X])\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]\n",
    "        return x, self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather Pre-Training Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_glove():\n",
    "    ! wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "    ! mkdir data\n",
    "    ! unzip glove.6B.zip\n",
    "    \n",
    "def delete_rare_words(word_vecs, word_count, min_df=4):\n",
    "    words_delete = []\n",
    "    for word in word_count:\n",
    "        if word_count[word] < min_df and word not in word_vecs:\n",
    "            words_delete.append(word)\n",
    "    for word in words_delete: word_count.pop(word)\n",
    "    return word_count\n",
    "\n",
    "def loadGloveModel(gloveFile=\"glove.6B.50d.txt\"):\n",
    "    \"\"\" Loads word vecgors into a dictionary\"\"\"\n",
    "    f = open(gloveFile,'r')\n",
    "    word_vecs = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        word_vecs[word] = np.array([float(val) for val in splitLine[1:]])\n",
    "    return word_vecs\n",
    "\n",
    "def create_embedding_matrix(word_vecs, word_count, min_df=4, emb_size=50):\n",
    "    \"\"\"Creates embedding matrix from word vectors. \"\"\"\n",
    "    word_count = delete_rare_words(word_vecs, word_count, min_df)\n",
    "    V = len(word_count.keys()) + 2\n",
    "    vocab2index = {}\n",
    "    W = np.zeros((V, emb_size), dtype=\"float32\")\n",
    "    vocab = [\"\", \"UNK\"]\n",
    "    # adding a vector for padding\n",
    "    W[0] = np.zeros(emb_size, dtype='float32')\n",
    "    # adding a vector for rare words \n",
    "    W[1] = np.random.uniform(-0.25, 0.25, emb_size)\n",
    "    vocab2index[\"UNK\"] = 1\n",
    "    i = 2\n",
    "    for word in word_count:\n",
    "        if word in word_vecs:\n",
    "            W[i] = word_vecs[word]\n",
    "            vocab2index[word] = i\n",
    "            vocab.append(word)\n",
    "            i += 1\n",
    "        else:\n",
    "            W[i] = np.random.uniform(-0.25,0.25, emb_size)\n",
    "            vocab2index[word] = i\n",
    "            vocab.append(word)\n",
    "            i += 1   \n",
    "    return W, np.array(vocab), vocab2index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tweet_CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, glove_weights=None):\n",
    "        super(Net, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, emb_size, padding_idx = 0)\n",
    "        if glove_weights is not None:\n",
    "            self.embeddings.weight.data.copy_(torch.from_numpy(glove_weights))\n",
    "            \n",
    "        self.conv1 = nn.Conv1d(emb_size, 100, 5, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(emb_size, 100, 5, kernel_size=2)\n",
    "        self.conv3 = nn.Conv1d(emb_size, 100, 5, kernel_size=3)\n",
    "        \n",
    "        self.pool1 = nn.MaxPoo11d(kernel_size = 26)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size = 25)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size = 24)\n",
    "        \n",
    "        self.bn = nn.BatchNorm1d(300)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.fc = nn.Linear(300, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        x = x.transpose(1,2)\n",
    "        x1 = self.pool(F.relu(self.conv1(x)))\n",
    "        x2 = self.pool(F.relu(self.conv2(x)))\n",
    "        x3 = self.pool(F.relu(self.conv3(x)))\n",
    "        out = torch.cat([x1, x2, x3], 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.dropout(self.bn(out))\n",
    "        \n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epocs(model, optimizer, epochs=10):\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        total = 0\n",
    "        for x, y in train_dl:\n",
    "            x = x.long()\n",
    "            y = y.float().unsqueeze(1)\n",
    "            out = model(x)\n",
    "            loss = F.binary_cross_entropy_with_logits(out, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += x.size(0)*loss.item()\n",
    "            total += x.size(0)\n",
    "        train_loss = total_loss/total\n",
    "        val_loss, val_accuracy = valid_metrics(model)\n",
    "        \n",
    "        print(\"train_loss %.3f val_loss %.3f val_accuracy %.3f\" % (\n",
    "            train_loss, val_loss, val_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TweetDataset(X_train, y_train)\n",
    "valid_ds = TweetDataset(X_val, y_val)\n",
    "train_dl = DataLoader(train_ds, batch_size=2, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,  357, 2356,    1, 2136,    1, 1331,  602,    1,    1,\n",
       "            1,    1],\n",
       "        [   0,    0,    0,    0,    0,    0,    0,    0,    0, 2090,    3,  418,\n",
       "          419,  420,  421,  422,   51,  423,  424,    9, 1100,   99, 1735, 1423,\n",
       "            1,    1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = len(words)\n",
    "emb_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = nn.Embedding(V, emb_size, padding_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernal = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = embed(x.long())\n",
    "x1 = x1.transpose(1,2)\n",
    "x1.size()\n",
    "conv_1 = nn.Conv1d(in_channels=emb_size, out_channels=100, kernel_size=1)\n",
    "x1 = F.relu(conv_1(x1))\n",
    "pool1 = nn.MaxPool1d(kernel_size = 26)\n",
    "x1 = pool1(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.MaxPool1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Kernal = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = embed(x.long())\n",
    "x2 = x2.transpose(1,2)\n",
    "x2.size()\n",
    "conv_2 = nn.Conv1d(in_channels=emb_size, out_channels=100, kernel_size=2)\n",
    "x2 = F.relu(conv_2(x2))\n",
    "pool2 = nn.MaxPool1d(kernel_size = 25)\n",
    "x2 = pool2(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Kernal = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = embed(x.long())\n",
    "x3 = x3.transpose(1,2)\n",
    "x3.size()\n",
    "conv_3 = nn.Conv1d(in_channels=emb_size, out_channels=100, kernel_size=3)\n",
    "x3 = F.relu(conv_3(x3))\n",
    "pool3 = nn.MaxPool1d(kernel_size = 24)\n",
    "x3 = pool3(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.cat([x1, x2, x3], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3934, 0.4180, 0.1096],\n",
       "         [1.6549, 0.6368, 0.6135],\n",
       "         [0.1761, 0.5728, 0.4253],\n",
       "         [0.9770, 0.7884, 0.3343],\n",
       "         [0.8955, 0.8736, 0.9640],\n",
       "         [0.2138, 0.5802, 0.8174],\n",
       "         [0.8102, 0.7806, 0.0000],\n",
       "         [0.4834, 0.7983, 0.5853],\n",
       "         [0.4859, 0.7846, 0.2344],\n",
       "         [0.0000, 0.3353, 0.3590],\n",
       "         [0.6423, 0.9788, 0.5589],\n",
       "         [0.5552, 0.5459, 0.6589],\n",
       "         [0.9799, 0.9322, 0.6591],\n",
       "         [0.6362, 0.8670, 0.9610],\n",
       "         [0.0000, 0.6415, 0.9623],\n",
       "         [1.1013, 0.0000, 0.4231],\n",
       "         [1.6403, 1.0163, 0.8996],\n",
       "         [0.5591, 0.6180, 1.0517],\n",
       "         [0.4567, 0.7392, 0.4556],\n",
       "         [0.3990, 1.3885, 0.3466],\n",
       "         [0.0000, 0.8018, 0.6271],\n",
       "         [0.0000, 0.6095, 0.0000],\n",
       "         [0.2778, 0.5612, 0.2590],\n",
       "         [0.2340, 0.1504, 0.2391],\n",
       "         [0.0000, 0.5153, 0.9233],\n",
       "         [0.3141, 0.4403, 0.5615],\n",
       "         [0.8181, 0.7354, 0.8874],\n",
       "         [0.0000, 1.0957, 0.4820],\n",
       "         [1.3228, 0.2316, 0.1625],\n",
       "         [0.5783, 0.5979, 0.8183],\n",
       "         [0.4920, 0.7274, 0.0000],\n",
       "         [0.0000, 0.7936, 0.3552],\n",
       "         [0.9978, 0.2403, 1.1096],\n",
       "         [0.1220, 0.4726, 0.4052],\n",
       "         [0.6049, 1.0306, 0.8178],\n",
       "         [0.8531, 0.7404, 1.2327],\n",
       "         [0.6855, 0.7244, 0.1659],\n",
       "         [0.2610, 0.7153, 0.0000],\n",
       "         [0.4975, 0.0000, 0.0000],\n",
       "         [0.4570, 0.6049, 0.3821],\n",
       "         [0.5923, 0.7473, 0.6795],\n",
       "         [0.4237, 0.3222, 0.5926],\n",
       "         [0.0000, 0.3717, 0.2902],\n",
       "         [0.6656, 0.0000, 0.5748],\n",
       "         [0.3537, 0.4017, 0.4191],\n",
       "         [0.0000, 0.0000, 0.7417],\n",
       "         [0.0000, 0.9021, 0.0272],\n",
       "         [0.0000, 0.6912, 0.9628],\n",
       "         [0.9043, 0.8625, 0.1053],\n",
       "         [0.0186, 0.0000, 0.4289],\n",
       "         [0.0000, 0.8522, 0.0000],\n",
       "         [0.0000, 0.8408, 0.8414],\n",
       "         [0.3617, 0.0000, 0.0000],\n",
       "         [0.6792, 0.0316, 0.2071],\n",
       "         [0.6860, 0.5975, 0.3779],\n",
       "         [0.0000, 0.3494, 0.7337],\n",
       "         [0.8386, 0.8421, 0.7682],\n",
       "         [1.3390, 0.2658, 0.2000],\n",
       "         [0.1301, 0.1607, 0.4550],\n",
       "         [0.4354, 0.2716, 0.2868],\n",
       "         [0.8567, 0.2180, 0.2504],\n",
       "         [0.5254, 0.4153, 0.6857],\n",
       "         [0.0041, 0.6703, 0.5728],\n",
       "         [1.1442, 0.2856, 0.3117],\n",
       "         [0.2343, 0.0000, 0.5143],\n",
       "         [0.1981, 0.2894, 0.3112],\n",
       "         [0.0000, 0.0777, 0.5987],\n",
       "         [0.2190, 0.2936, 0.3693],\n",
       "         [0.2634, 0.7410, 0.9927],\n",
       "         [0.1964, 0.6183, 0.6169],\n",
       "         [0.1794, 1.2450, 0.6503],\n",
       "         [0.6903, 0.5482, 0.9847],\n",
       "         [0.7103, 0.8594, 0.3013],\n",
       "         [0.0000, 0.3249, 0.4206],\n",
       "         [0.5916, 0.7858, 0.4914],\n",
       "         [0.3678, 0.8143, 0.8999],\n",
       "         [0.1055, 1.0210, 0.5395],\n",
       "         [1.3625, 0.8601, 0.7119],\n",
       "         [1.5137, 0.0504, 0.1908],\n",
       "         [0.0000, 0.2322, 0.8686],\n",
       "         [0.0000, 0.6340, 0.5704],\n",
       "         [0.2004, 0.5682, 0.8001],\n",
       "         [0.9957, 0.9528, 0.4062],\n",
       "         [0.6577, 0.4214, 0.4843],\n",
       "         [0.4040, 0.2757, 0.7511],\n",
       "         [0.0000, 0.0000, 0.3710],\n",
       "         [0.4734, 0.1555, 0.8565],\n",
       "         [0.3215, 0.1863, 0.3779],\n",
       "         [0.0000, 0.0000, 0.0307],\n",
       "         [0.6206, 0.9543, 0.6593],\n",
       "         [0.2186, 0.0878, 0.2296],\n",
       "         [0.2834, 0.6074, 0.0875],\n",
       "         [0.4932, 0.3407, 0.6299],\n",
       "         [0.5712, 0.4010, 0.0000],\n",
       "         [0.3963, 0.0000, 0.5939],\n",
       "         [1.0149, 0.3017, 0.1648],\n",
       "         [0.3100, 0.2945, 0.8583],\n",
       "         [0.9008, 0.5238, 0.9623],\n",
       "         [0.0000, 0.7729, 0.2452],\n",
       "         [0.4160, 0.6998, 0.4824]],\n",
       "\n",
       "        [[1.0557, 0.7438, 0.8121],\n",
       "         [2.3075, 0.9809, 0.9127],\n",
       "         [1.1489, 0.9291, 0.9052],\n",
       "         [2.1612, 1.2901, 1.2183],\n",
       "         [1.2156, 1.5750, 1.5272],\n",
       "         [0.4197, 0.8747, 1.3798],\n",
       "         [1.2216, 1.0406, 0.1990],\n",
       "         [1.0545, 1.7548, 1.4497],\n",
       "         [1.5631, 1.5373, 1.0273],\n",
       "         [0.8685, 0.8580, 1.0742],\n",
       "         [1.0716, 1.2879, 1.0453],\n",
       "         [1.6290, 1.0532, 1.0776],\n",
       "         [1.6798, 1.0013, 0.6919],\n",
       "         [0.9976, 1.2532, 1.3201],\n",
       "         [1.1334, 1.3398, 1.2670],\n",
       "         [1.6877, 0.6928, 1.5497],\n",
       "         [2.2815, 1.6060, 1.6091],\n",
       "         [1.2914, 1.5729, 1.5205],\n",
       "         [1.2993, 1.2791, 0.8712],\n",
       "         [1.1293, 1.6780, 1.8016],\n",
       "         [0.9577, 1.6025, 1.8414],\n",
       "         [0.4161, 1.7320, 0.3022],\n",
       "         [0.7128, 1.1685, 0.8594],\n",
       "         [1.2212, 0.4124, 0.8381],\n",
       "         [0.9562, 0.8568, 1.3538],\n",
       "         [0.5324, 0.8431, 1.9405],\n",
       "         [1.5345, 0.8678, 1.0047],\n",
       "         [0.5200, 2.6935, 1.3220],\n",
       "         [1.8228, 0.9514, 1.2114],\n",
       "         [1.6693, 0.9881, 2.1185],\n",
       "         [1.4569, 0.6926, 0.1501],\n",
       "         [0.9948, 1.3481, 0.6682],\n",
       "         [1.1934, 0.7272, 1.7912],\n",
       "         [0.7384, 1.0146, 0.8188],\n",
       "         [1.4647, 1.2697, 1.2435],\n",
       "         [2.0552, 1.0401, 1.5917],\n",
       "         [0.9601, 1.0599, 0.6622],\n",
       "         [1.5142, 1.7026, 0.5182],\n",
       "         [1.1890, 1.0860, 0.8717],\n",
       "         [1.2823, 0.8952, 0.2456],\n",
       "         [1.4810, 1.4787, 1.2771],\n",
       "         [1.4033, 1.4430, 1.0769],\n",
       "         [0.0241, 1.2123, 1.3040],\n",
       "         [1.5801, 0.7320, 1.0556],\n",
       "         [0.7191, 1.0086, 0.5605],\n",
       "         [0.9937, 1.1796, 1.3669],\n",
       "         [1.0262, 1.4998, 1.0106],\n",
       "         [0.5289, 1.0370, 1.7114],\n",
       "         [1.5419, 1.1327, 1.0736],\n",
       "         [0.6412, 0.7299, 1.3359],\n",
       "         [0.2979, 1.6181, 0.4671],\n",
       "         [0.4751, 0.9489, 1.2474],\n",
       "         [0.7787, 0.5067, 0.2675],\n",
       "         [1.5651, 0.8295, 0.7709],\n",
       "         [1.3966, 1.5503, 0.8749],\n",
       "         [0.6788, 0.9048, 1.9952],\n",
       "         [1.6240, 1.5303, 1.4849],\n",
       "         [1.8582, 0.6872, 0.8363],\n",
       "         [1.0726, 0.8207, 1.0200],\n",
       "         [1.5454, 0.8212, 0.5667],\n",
       "         [1.0338, 0.6309, 1.1289],\n",
       "         [1.5333, 1.5291, 1.1040],\n",
       "         [1.0581, 0.9632, 1.0315],\n",
       "         [1.2206, 0.8771, 1.0138],\n",
       "         [0.5208, 0.7846, 1.4714],\n",
       "         [0.8017, 0.6349, 1.1214],\n",
       "         [0.3350, 0.7885, 1.4555],\n",
       "         [1.3508, 1.3058, 0.7379],\n",
       "         [0.7140, 1.4405, 1.3635],\n",
       "         [0.4335, 0.9095, 0.7366],\n",
       "         [1.4775, 2.3355, 1.1687],\n",
       "         [1.2831, 0.8885, 2.0053],\n",
       "         [1.5845, 1.2677, 1.1490],\n",
       "         [0.6656, 0.9380, 0.9615],\n",
       "         [0.9601, 1.7456, 0.9783],\n",
       "         [0.7767, 1.4388, 1.3560],\n",
       "         [1.1464, 1.6751, 0.9409],\n",
       "         [2.0534, 0.8051, 0.5689],\n",
       "         [2.2597, 0.5242, 0.6878],\n",
       "         [0.1034, 0.8142, 1.6150],\n",
       "         [0.5981, 1.4701, 0.8104],\n",
       "         [0.8135, 1.4719, 0.7699],\n",
       "         [1.6560, 1.5434, 1.0940],\n",
       "         [1.9147, 1.8291, 1.2199],\n",
       "         [0.9359, 1.2625, 1.5399],\n",
       "         [1.0557, 0.3561, 0.6850],\n",
       "         [1.1007, 0.9713, 1.1691],\n",
       "         [1.1157, 1.1984, 0.8110],\n",
       "         [0.7061, 1.1969, 0.2111],\n",
       "         [1.1501, 1.3904, 1.6760],\n",
       "         [1.0375, 0.4394, 0.9391],\n",
       "         [1.1989, 1.1854, 0.6337],\n",
       "         [1.5283, 0.8088, 1.3928],\n",
       "         [1.1358, 0.7067, 0.8420],\n",
       "         [0.9835, 0.5717, 1.1604],\n",
       "         [1.8588, 0.6219, 0.6176],\n",
       "         [0.5502, 0.6412, 2.0064],\n",
       "         [1.4572, 1.1731, 1.4128],\n",
       "         [0.2224, 1.1556, 0.7416],\n",
       "         [1.1717, 1.4265, 0.9309]]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out.view(out.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = nn.Dropout(p=0.2)\n",
    "out = dropout(bn(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = nn.BatchNorm1d(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster = pd.read_csv('nlp-getting-started/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(disaster.text)\n",
    "y = np.array(disaster.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = get_vocab(X_train)\n",
    "for word in list(word_count):\n",
    "    if word_count[word] < 5:\n",
    "        del word_count[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2index = {\"<PAD>\":0, \"UNK\":1} # init with padding and unknown\n",
    "words = [\"<PAD>\", \"UNK\"]\n",
    "for word in word_count:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
